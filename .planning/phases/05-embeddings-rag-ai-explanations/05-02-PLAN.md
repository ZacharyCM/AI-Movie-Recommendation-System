---
phase: 05-embeddings-rag-ai-explanations
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - backend/config.py
  - backend/services/explanations.py
  - backend/routers/recommendations.py
  - backend/schemas/recommendation.py
  - backend/dependencies.py
  - backend/main.py
  - frontend/src/lib/api.ts
  - frontend/src/hooks/useExplanation.ts
  - frontend/src/components/recommendations/ExplanationButton.tsx
  - frontend/src/components/recommendations/RecommendationSection.tsx
autonomous: true
user_setup:
  - service: anthropic
    why: "Claude API for generating natural language explanations"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "https://console.anthropic.com/settings/keys -> Create Key"

must_haves:
  truths:
    - "User can click 'Why this?' on any recommendation and see a natural language explanation"
    - "Explanation references specific movies the user rated highly and why the recommended movie connects to their taste"
    - "Explanation combines content similarity and collaborative signals in natural language"
    - "Repeated clicks on 'Why this?' load cached explanation instantly without calling Claude API again"
    - "All movies mentioned in explanations exist in the catalog (no hallucinated titles)"
  artifacts:
    - path: "backend/services/explanations.py"
      provides: "ExplanationService with RAG pipeline"
      exports: ["ExplanationService"]
    - path: "backend/routers/recommendations.py"
      provides: "GET /api/recommendations/{movie_id}/explain endpoint"
      contains: "explain"
    - path: "backend/schemas/recommendation.py"
      provides: "ExplanationResponse schema"
      contains: "ExplanationResponse"
    - path: "frontend/src/hooks/useExplanation.ts"
      provides: "React hook for fetching explanations"
      exports: ["useExplanation"]
    - path: "frontend/src/components/recommendations/ExplanationButton.tsx"
      provides: "'Why this?' button with lazy-loaded explanation"
      exports: ["ExplanationButton"]
  key_links:
    - from: "frontend/src/components/recommendations/ExplanationButton.tsx"
      to: "/api/recommendations/{movie_id}/explain"
      via: "useExplanation hook triggered on button click"
      pattern: "useExplanation"
    - from: "backend/routers/recommendations.py"
      to: "backend/services/explanations.py"
      via: "ExplanationService.get_explanation() call"
      pattern: "explanation_service"
    - from: "backend/services/explanations.py"
      to: "backend/ml/embeddings/store.py"
      via: "ChromaDB retrieval for similar movies context"
      pattern: "embedding_store"
    - from: "backend/services/explanations.py"
      to: "anthropic"
      via: "Claude API call for explanation generation"
      pattern: "client.messages.create"
---

<objective>
Implement AI-powered recommendation explanations using a RAG pipeline (ChromaDB retrieval + Claude generation) with PostgreSQL caching and a "Why this?" button in the frontend.

Purpose: This is the CORE DIFFERENTIATOR of the project. Users understand WHY each recommendation fits their taste through natural language explanations that reference their personal rating history and multiple recommendation factors.

Output: Working "Why this?" button on recommendation cards that generates and displays cached AI explanations.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-embeddings-rag-ai-explanations/05-RESEARCH.md
@.planning/phases/05-embeddings-rag-ai-explanations/05-01-SUMMARY.md

@backend/config.py
@backend/dependencies.py
@backend/main.py
@backend/services/recommender.py
@backend/routers/recommendations.py
@backend/schemas/recommendation.py
@frontend/src/lib/api.ts
@frontend/src/hooks/useRecommendations.ts
@frontend/src/components/recommendations/RecommendationSection.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ExplanationService with RAG pipeline, caching, and API endpoint</name>
  <files>
    backend/config.py
    backend/services/explanations.py
    backend/routers/recommendations.py
    backend/schemas/recommendation.py
    backend/dependencies.py
    backend/main.py
    backend/requirements.txt
  </files>
  <action>
    1. Add `anthropic` to `backend/requirements.txt`. Run `pip install anthropic`.

    2. Add `anthropic_api_key: str = ""` to `Settings` class in `backend/config.py`.

    3. Add `ExplanationResponse` schema to `backend/schemas/recommendation.py`:
       ```python
       class ExplanationResponse(BaseModel):
           movie_id: int
           explanation: str
           factors: list[str]  # e.g., ["content_similarity", "collaborative_filtering"]
           cached: bool  # whether this was served from cache
       ```

    4. Create `backend/services/explanations.py` with `ExplanationService` class:

       **Constructor:** Takes Supabase client URL/key (from config), creates AsyncAnthropic client, imports EmbeddingStore.

       **get_explanation(user_id, movie_id) -> dict:** Main method implementing the RAG pipeline:

       a. **CACHE CHECK:** Query Supabase `ai_explanations` table for (user_id, movie_id). If found and not expired (< 7 days old), return cached result with `cached: true`.

       b. **RETRIEVAL:** Get context for Claude:
          - Fetch user's ratings from Supabase (top 10 highest-rated movies, sorted by rating desc).
          - For each rated movie, get title/genres from TMDB or stored metadata.
          - Get the target recommended movie's metadata from TMDB.
          - Query ChromaDB (EmbeddingStore) for 3 movies most similar to the target movie (for "movies like this" context).
          - Get the recommendation strategy for this user (from recommender_service: content_based, hybrid, etc.).

       c. **AUGMENTATION:** Build structured prompt for Claude:
          ```
          You are a movie recommendation assistant. Explain WHY this user will enjoy the recommended movie.

          <user_taste>
          Movies they loved (rated 4-5 stars):
          - {title} ({year}) - {genres} - rated {rating}/5
          ...
          </user_taste>

          <recommended_movie>
          {title} ({year})
          {overview}
          Genres: {genres}
          Director: {director}
          </recommended_movie>

          <similar_movies_in_catalog>
          Movies similar to the recommendation:
          - {title} ({year}) - {genres}
          ...
          </similar_movies_in_catalog>

          <recommendation_context>
          This movie was recommended via {strategy} algorithm.
          </recommendation_context>

          Generate a 2-3 sentence explanation connecting the recommended movie to their taste.
          Rules:
          - Reference specific movies they rated highly by name
          - Mention shared genres, themes, directors, or cast
          - If collaborative filtering was used, mention "users with similar taste also enjoyed..."
          - Be conversational and natural, like a friend recommending a movie
          - ONLY reference movies listed above. NEVER mention movies not in the provided context.
          - Output valid JSON: {"explanation": "...", "factors": ["content_similarity", ...]}
          ```

          Valid factors: "content_similarity", "collaborative_filtering", "genre_match", "director_match", "thematic_similarity"

       d. **GENERATION:** Call Claude API:
          - Use `anthropic.AsyncAnthropic(api_key=settings.anthropic_api_key)`.
          - Model: `claude-sonnet-4-5-20250929` (cost-effective for short explanations).
          - `max_tokens=400`, `temperature=0.7`.
          - Parse JSON response. If JSON parsing fails, wrap raw text in default structure.

       e. **CACHE STORE:** Insert result into Supabase `ai_explanations` table with `generated_at` timestamp and 7-day `expires_at`.

       f. **Return** explanation dict with `cached: false`.

       **Error handling:**
       - If Claude API fails (rate limit, network), return a graceful fallback: "This movie was recommended based on your taste for {genres}."
       - If ChromaDB query fails, proceed without similar movies context.
       - Log all errors but never let them bubble to user as 500s.

    5. Create Supabase `ai_explanations` table. Add a migration comment in the service file documenting the required table schema:
       ```sql
       -- Required table (create via Supabase dashboard or migration):
       -- CREATE TABLE ai_explanations (
       --   user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
       --   movie_id INTEGER NOT NULL,
       --   explanation TEXT NOT NULL,
       --   factors TEXT[] DEFAULT '{}',
       --   generated_at TIMESTAMPTZ DEFAULT NOW(),
       --   expires_at TIMESTAMPTZ DEFAULT (NOW() + INTERVAL '7 days'),
       --   PRIMARY KEY (user_id, movie_id)
       -- );
       -- CREATE INDEX idx_ai_explanations_expires ON ai_explanations(expires_at);
       ```

       Also programmatically create the table in the service's init if it doesn't exist, using the Supabase service role client to run the SQL. This way it's self-bootstrapping.

    6. Add `GET /api/recommendations/{movie_id}/explain` endpoint to `backend/routers/recommendations.py`:
       - Requires Bearer token auth (reuse existing `get_current_user_id`).
       - Calls `ExplanationService().get_explanation(user_id, movie_id)`.
       - Returns `ExplanationResponse`.
       - Handles errors with appropriate HTTP status codes.

    7. Update `backend/dependencies.py` to create a shared `EmbeddingStore` instance (imported and used by ExplanationService).

    8. Update `backend/main.py` lifespan to initialize embedding store on startup (verify ChromaDB collection exists and log count).

    Important: Use `AsyncAnthropic` client (not sync `Anthropic`) since FastAPI is async. The anthropic SDK handles retries automatically -- do NOT add custom retry logic.
  </action>
  <verify>
    Run: `cd backend && python -c "from services.explanations import ExplanationService; print('ExplanationService imported successfully')"` -- should succeed.

    Start the server: `cd backend && uvicorn main:app --reload` -- should log embedding store count on startup.

    If ANTHROPIC_API_KEY is set, test: `curl -H "Authorization: Bearer {token}" http://localhost:8000/api/recommendations/550/explain` -- should return explanation JSON.
  </verify>
  <done>
    ExplanationService implements full RAG pipeline: cache check -> retrieval (ratings + embeddings + metadata) -> Claude generation -> cache store. API endpoint returns explanation with factors. Graceful fallback on Claude API failure. AsyncAnthropic client used throughout.
  </done>
</task>

<task type="auto">
  <name>Task 2: Build "Why this?" button component and integrate into recommendation cards</name>
  <files>
    frontend/src/lib/api.ts
    frontend/src/hooks/useExplanation.ts
    frontend/src/components/recommendations/ExplanationButton.tsx
    frontend/src/components/recommendations/RecommendationSection.tsx
  </files>
  <action>
    1. Add `fetchExplanation` function to `frontend/src/lib/api.ts`:
       ```typescript
       export interface ExplanationResponse {
         movie_id: number;
         explanation: string;
         factors: string[];
         cached: boolean;
       }

       export async function fetchExplanation(
         accessToken: string,
         movieId: number
       ): Promise<ExplanationResponse> {
         const res = await fetch(
           `${API_URL}/api/recommendations/${movieId}/explain`,
           {
             cache: "no-store",
             headers: {
               Authorization: `Bearer ${accessToken}`,
             },
           }
         );
         if (!res.ok) throw new Error(res.statusText);
         return res.json();
       }
       ```

    2. Create `frontend/src/hooks/useExplanation.ts`:
       - Uses TanStack Query with `queryKey: ['explanation', movieId]`.
       - `queryFn` gets Supabase session token and calls `fetchExplanation`.
       - `enabled: !!movieId` -- only fetches when movieId is provided (lazy loading).
       - `staleTime: Infinity` -- explanations don't change unless ratings change.
       - `retry: 1` -- single retry on failure.

    3. Create `frontend/src/components/recommendations/ExplanationButton.tsx`:
       - Props: `{ movieId: number }`.
       - State: `showExplanation` boolean (starts false).
       - On click, toggles `showExplanation`. The `useExplanation` hook only fires when `showExplanation` is true (pass `showExplanation ? movieId : null`).
       - Renders a "Why this?" text button (small, subtle, uses Tailwind: `text-sm text-blue-400 hover:text-blue-300`).
       - When expanded, shows:
         - Loading state: "Generating explanation..." with a subtle pulse animation.
         - Error state: "Unable to load explanation" in muted text.
         - Success state: The explanation text in a styled card (bg-slate-800/50, rounded-lg, p-3, text-slate-300).
         - Factor pills: Small badges showing factors like "Content Similarity", "Genre Match" (bg-slate-700, text-xs, rounded-full, px-2, py-0.5).
       - Use Framer Motion for smooth expand/collapse animation (`AnimatePresence` + `motion.div`).
       - Prevent click events from bubbling to parent Link (stopPropagation).

    4. Update `frontend/src/components/recommendations/RecommendationSection.tsx`:
       - Import `ExplanationButton`.
       - Add `ExplanationButton` below each `MovieCard` in the recommendation list.
       - Only show for non-popularity-fallback strategies (strategies that actually use personalization).
       - Pass `movieId={movie.id}` to each ExplanationButton.
       - Adjust layout: each recommendation item becomes a flex column with MovieCard on top and ExplanationButton below.

    Design notes:
    - Match dark theme: slate-800/slate-700 backgrounds, slate-300 text, blue-400 accent.
    - Keep ExplanationButton compact -- it should feel like a natural extension of the card, not a separate section.
    - Factor labels should be human-readable: "content_similarity" -> "Content Similarity", "collaborative_filtering" -> "Similar Users".
  </action>
  <verify>
    Run: `cd frontend && pnpm build` -- should compile without TypeScript errors.

    Manual test: Navigate to browse page with recommendations, click "Why this?" on a recommendation card, verify explanation appears with smooth animation.
  </verify>
  <done>
    "Why this?" button appears on each recommendation card (except popularity fallback). Clicking it lazy-loads an AI explanation via the backend API. Explanations display in a styled card with factor pills. Smooth Framer Motion expand/collapse animation. Cached explanations load instantly on repeat clicks.
  </done>
</task>

</tasks>

<verification>
1. Backend: `GET /api/recommendations/{movie_id}/explain` returns valid JSON with explanation, factors, and cached fields.
2. Caching: Second request for same (user, movie) pair returns `cached: true` and loads faster.
3. Frontend: "Why this?" button visible on recommendation cards, click triggers explanation fetch, explanation displays with animation.
4. Hallucination check: Explanation only references movies from the user's actual rating history and catalog.
5. Error handling: If ANTHROPIC_API_KEY is not set, endpoint returns graceful fallback explanation.
</verification>

<success_criteria>
- User can click "Why this?" on any recommendation and see a natural language explanation.
- Explanations reference the user's specific rated movies and shared attributes.
- Explanations mention multiple factors (content similarity, collaborative signals) naturally.
- Cached explanations load instantly without Claude API calls.
- No hallucinated movie titles in explanations.
</success_criteria>

<output>
After completion, create `.planning/phases/05-embeddings-rag-ai-explanations/05-02-SUMMARY.md`
</output>
