---
phase: 05-embeddings-rag-ai-explanations
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/requirements.txt
  - backend/ml/embeddings/__init__.py
  - backend/ml/embeddings/builder.py
  - backend/ml/embeddings/store.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Movie embeddings are generated from the TF-IDF movie catalog and persisted in ChromaDB"
    - "ChromaDB collection contains one embedding per movie with title, genres, and year metadata"
    - "Embedding builder script can be re-run idempotently without duplicating data (uses upsert)"
  artifacts:
    - path: "backend/ml/embeddings/__init__.py"
      provides: "Package marker"
    - path: "backend/ml/embeddings/builder.py"
      provides: "Embedding generation script"
      contains: "SentenceTransformer"
    - path: "backend/ml/embeddings/store.py"
      provides: "ChromaDB interface for query and retrieval"
      exports: ["EmbeddingStore"]
    - path: "backend/requirements.txt"
      provides: "Updated dependencies"
      contains: "chromadb"
  key_links:
    - from: "backend/ml/embeddings/builder.py"
      to: "backend/ml/embeddings/store.py"
      via: "EmbeddingStore class used for persistence"
      pattern: "EmbeddingStore"
    - from: "backend/ml/embeddings/builder.py"
      to: "backend/ml/build_model.py"
      via: "Reuses TMDB fetch pattern and movie_ids from TF-IDF catalog"
      pattern: "movie_ids"
---

<objective>
Generate and persist movie embeddings in ChromaDB using sentence-transformers (all-MiniLM-L6-v2).

Purpose: ChromaDB embeddings are the foundation for both semantic search (Plan 05-03) and RAG context retrieval for AI explanations (Plan 05-02). Without embeddings, neither feature can function.

Output: ChromaDB persistent database at `backend/ml/embeddings/chroma_db/` with embeddings for all movies in the TF-IDF catalog, plus a reusable `EmbeddingStore` class for querying.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-embeddings-rag-ai-explanations/05-RESEARCH.md

@backend/ml/build_model.py
@backend/requirements.txt
@backend/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install dependencies and create EmbeddingStore ChromaDB interface</name>
  <files>
    backend/requirements.txt
    backend/ml/embeddings/__init__.py
    backend/ml/embeddings/store.py
  </files>
  <action>
    1. Add `chromadb` and `sentence-transformers` to `backend/requirements.txt`.

    2. Create `backend/ml/embeddings/__init__.py` (empty package marker).

    3. Create `backend/ml/embeddings/store.py` with an `EmbeddingStore` class:
       - Constructor takes optional `persist_dir` (defaults to `backend/ml/embeddings/chroma_db`).
       - Uses `chromadb.PersistentClient(path=persist_dir)` for development (single-worker).
       - `get_or_create_collection(name="movies")` with `metadata={"hnsw:space": "cosine"}` for cosine similarity.
       - `upsert_movies(ids, embeddings, documents, metadatas)` method -- wraps `collection.upsert()`.
       - `query_similar(query_embedding, n_results=10)` method -- wraps `collection.query()`, returns list of dicts with `id`, `document`, `metadata`, `distance`.
       - `get_by_ids(ids: list[str])` method -- wraps `collection.get()` for direct lookup.
       - `count()` method -- returns number of embeddings stored.
       - All methods include basic error handling with logging.

    Use chromadb PersistentClient (not HttpClient) per research recommendation for development. The store is a thin wrapper -- do NOT over-abstract. Keep it simple.
  </action>
  <verify>
    Run: `cd backend && pip install chromadb sentence-transformers && python -c "from ml.embeddings.store import EmbeddingStore; s = EmbeddingStore(); print(f'Collection count: {s.count()}')"` -- should print "Collection count: 0" without errors.
  </verify>
  <done>
    chromadb and sentence-transformers installed. EmbeddingStore class exists with upsert, query, get_by_ids, and count methods. PersistentClient creates chroma_db directory on first use.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create embedding builder script and generate movie embeddings</name>
  <files>
    backend/ml/embeddings/builder.py
  </files>
  <action>
    Create `backend/ml/embeddings/builder.py` following the pattern of `backend/ml/build_model.py`:

    1. Load the existing TF-IDF movie catalog:
       - Load `movie_ids.pkl` from `backend/ml/models/` (the same movie IDs the TF-IDF model was built on).
       - For each movie ID, fetch details from TMDB (title, overview, genres, director, cast) using the same `fetch_movie_details` pattern from `build_model.py`.

    2. Build text representations for embedding:
       - Combine: title + overview + "Genres: {genre_list}" + "Director: {director_name}" + "Cast: {top_3_cast}".
       - This is similar to `build_metadata_soup()` but keep names readable (don't strip spaces -- sentence-transformers handles natural text better than TF-IDF).

    3. Generate embeddings using sentence-transformers:
       - `model = SentenceTransformer('all-MiniLM-L6-v2')`.
       - `embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)`.

    4. Store in ChromaDB via EmbeddingStore:
       - Use `store.upsert_movies()` with:
         - `ids`: string movie IDs (e.g., ["123", "456"]).
         - `embeddings`: embedding vectors as lists.
         - `documents`: the text representations.
         - `metadatas`: list of dicts with `title`, `genres` (comma-separated string), `year` (from release_date[:4]).

    5. Add `main()` function as entry point, callable via `python -m ml.embeddings.builder` or `python ml/embeddings/builder.py`.

    6. Make the script idempotent -- uses `upsert` so re-running is safe.

    7. Include progress logging: "Processing movie X/N: Title".

    Important: Use the TMDB API key from `config.settings`. Rate-limit TMDB calls with `asyncio.sleep(0.25)` between requests (same pattern as build_model.py).
  </action>
  <verify>
    Run: `cd backend && python -m ml.embeddings.builder` -- should fetch movie details from TMDB, generate embeddings, store in ChromaDB. Verify with: `python -c "from ml.embeddings.store import EmbeddingStore; s = EmbeddingStore(); print(f'Stored {s.count()} embeddings')"` -- count should match number of movies in TF-IDF catalog (~250).
  </verify>
  <done>
    Embedding builder script generates 384-dim embeddings for all TF-IDF catalog movies and persists them in ChromaDB. Running `builder.py` produces a `chroma_db/` directory with cosine-similarity indexed embeddings. Script is idempotent via upsert.
  </done>
</task>

</tasks>

<verification>
1. `pip install -r backend/requirements.txt` succeeds with chromadb and sentence-transformers.
2. `python -m ml.embeddings.builder` runs without errors and produces embeddings.
3. `EmbeddingStore().count()` returns the expected number of movies.
4. `EmbeddingStore().query_similar(model.encode(["dark thriller"]).tolist()[0], n_results=5)` returns 5 relevant movies.
</verification>

<success_criteria>
- ChromaDB persistent database exists at `backend/ml/embeddings/chroma_db/`.
- EmbeddingStore class provides query_similar, upsert_movies, get_by_ids, count methods.
- All TF-IDF catalog movies have embeddings stored with title/genres/year metadata.
- Builder script is idempotent and follows existing project patterns.
</success_criteria>

<output>
After completion, create `.planning/phases/05-embeddings-rag-ai-explanations/05-01-SUMMARY.md`
</output>
